```{r load_libraries}
library(dplyr)
library(magrittr)
```


```{r load_data, cache=TRUE}

#batch_id <- args[1] #"2016_04_01_a549_48hr_batch1"
batch_id <- "2016_04_01_a549_48hr_batch1"

metadata_dir <- paste("../..", "metadata", batch_id, sep = "/")

backend_dir <- paste("../..", "backend", batch_id, sep = "/")

per_well_csv <- 
  tibble::data_frame(flist = 
                       list.files(backend_dir, 
                                  pattern = "*augmented.csv", 
                                  recursive = T, full.names = T)
  )

per_well_csv %<>% 
  rowwise() %>%
  mutate(Assay_Plate_Barcode = 
           stringr::str_split(basename(flist), "_")[[1]][1]
         ) %>%
  ungroup()

per_well_csv %<>% inner_join(
  readr::read_csv(paste(metadata_dir, "barcode_platemap.csv", sep = "/")) %>%
    select(Compound_Plate_Map_Name, Assay_Plate_Barcode)
)

per_well_csv %>% 
  count(Compound_Plate_Map_Name) %>%
  knitr::kable()

df <- lapply(per_well_csv$flist %>% normalizePath(), readr::read_csv) %>% bind_rows()

df %<>%
  mutate(Metadata_broad_sample_type = ifelse(is.na(Metadata_broad_sample), "control", "trt")) %>%
  mutate(Metadata_mg_per_ml = ifelse(Metadata_broad_sample_type =="control", 0, Metadata_mg_per_ml)) %>%
  mutate(Metadata_mmoles_per_liter = ifelse(Metadata_broad_sample_type =="control", 0, Metadata_mmoles_per_liter)) 
  
feature_cols <-
  colnames(df) %>%
  stringr::str_subset("^Nuclei_|^Cells_|^Cytoplasm_")

metadata_cols <-
  colnames(df) %>%
  stringr::str_subset("^Metadata_")

df %>% 
  count(Metadata_Compound_Plate_Map_Name, Metadata_Plate) %>%
  knitr::kable()
```


```{r variance_threshold}
df <-
  cytominr::select(
    population = df,
    variables = feature_cols,
    sample = df,
    operation = "variance_threshold"
  ) %>%
  dplyr::collect()

feature_cols <-
  colnames(df) %>%
  stringr::str_subset("^Nuclei_|^Cells_|^Cytoplasm_")
```


```{r feature_replicate_scores}
library(foreach)
library(doMC)
doMC::registerDoMC()

calculate_feature_replicate_correlation <- function(data, 
                                                    feature_col, 
                                                    grouping_cols, 
                                                    key_col) {

  nonkey_grouping_cols <- setdiff(grouping_cols, key_col)
  
  correlation_matrix <- 
    data %>%
    dplyr::arrange_(.dots = grouping_cols) %>%
    dplyr::select_(.dots = c(grouping_cols, feature_col)) %>% 
    tidyr::spread_(key_col, feature_col) %>% 
    dplyr::select_(~-dplyr::one_of(nonkey_grouping_cols)) %>%
    cor()
  
  median(correlation_matrix[upper.tri(correlation_matrix)])
}

calculate_feature_replicate_correlations <- 
  function(data, feature_cols, grouping_cols, key_col, split_col) {
  
  foreach::foreach(feature_col = feature_cols, .combine = rbind) %dopar%
    {
      
      data %>%
        split(.[split_col]) %>%
        purrr::map_df(calculate_feature_replicate_correlation, 
                      feature_col = feature_col,
                      grouping_cols = grouping_cols,
                      key_col = key_col) %>% 
        dplyr::mutate(feature_col = feature_col)
    } %>%
      tidyr::gather_(key_col, "pearson", setdiff(names(.), "feature_col")) %>% 
      dplyr::group_by(feature_col) %>% 
      dplyr::summarize_at("pearson", dplyr::funs(median, min, max))
}

```


```{r feature_replicate_scores_calculate, eval=FALSE}
feature_replicate_correlations <-
  df %>%
  filter(Metadata_broad_sample_type == "trt") %>%
  calculate_feature_replicate_correlations(
    feature_cols = feature_cols,
    split_col = "Metadata_Compound_Plate_Map_Name",
    grouping_cols = c("Metadata_Plate", "Metadata_Well"),
    key_col = "Metadata_Plate")

feature_replicate_correlations %>% 
  knitr::kable()

#feature_replicate_correlations  %>% readr::write_csv("feature_replicate_correlations.csv")

```


```{r filter_based_on_feature_replicate_correlations}

if(!exists("feature_replicate_correlations") & file.exists("feature_replicate_correlations.csv")) {
  futile.logger::flog.info("Reading feature_replicate_correlations from file.")
  feature_replicate_correlations <- readr::read_csv("feature_replicate_correlations.csv")
}

df %<>% 
  dplyr::select_(.dots = setdiff(x = colnames(df), 
        y = feature_replicate_correlations %>% 
          filter(min < 0.6) %>% 
          magrittr::extract2("feature_col"))
        )

feature_cols <-
  colnames(df) %>%
  stringr::str_subset("^Nuclei_|^Cells_|^Cytoplasm_")
```


```{r correlation_threshold}
df <-
  cytominr::select(
    population = df,
    variables = feature_cols,
    sample = df,
    operation = "correlation_threshold"
  ) %>%
  dplyr::collect()

feature_cols <-
  colnames(df) %>%
  stringr::str_subset("^Nuclei_|^Cells_|^Cytoplasm_")
```


```{r normalize}

futile.logger::flog.threshold(futile.logger::DEBUG)

normalized <-
  cytominr::normalize(
    population = df,
    variables = feature_cols,
    strata =  c("Metadata_Plate"),
    sample = df %>% dplyr::filter(Metadata_broad_sample_type == "control")
  )

# Check if data was normalized correctly by checking if mean of control wells
# is zero
normalized %>%
  dplyr::filter(Metadata_broad_sample_type == "control") %>%
  dplyr::group_by(Metadata_Plate) %>%
  dplyr::summarise_at(feature_cols, mean) %>%
  tidyr::gather(feature_col, error, -Metadata_Plate) %>%
  dplyr::group_by(feature_col) %>%
  dplyr::summarize(error = max(error)) %>%
  dplyr::summarize(max_error = max(error)) 
```

```{r eval=FALSE}

#X <- normalized 

X <- normalized %>% dplyr::filter(Metadata_Plate == "SQ00015116")

grouping_cols <- c("Metadata_Compound_Plate_Map_Name")

cmat <- X %>% dplyr::select_(.dots = feature_cols) %>% as.matrix() %>% t() %>% cor()

n <- nrow(X)

query_cols <- c("Metadata_Compound_Plate_Map_Name", 
                "Metadata_Plate", 
                "Metadata_Well", 
                "Metadata_broad_sample_type",
                "Metadata_broad_sample",
                "Metadata_mmoles_per_liter")
  
fac <- X %>% dplyr::select_(.dots = query_cols) %>% dplyr::mutate(index = 1:n)

memdb <- dplyr::src_sqlite(":memory:", create = T)

#fac <- dplyr::copy_to(memdb, fac, indexes = as.list(c(grouping_cols, "index")))
#fac <- dplyr::copy_to(memdb, fac, indexes = as.list(grouping_cols))
fac <- dplyr::copy_to(memdb, fac)

#fac_outer <- dplyr::left_join(fac, fac, by = grouping_cols)
#fac_outer <- dplyr::left_join(fac, fac, by = c("Metadata_Well"))

dplyr::explain(fac %>% dplyr::filter(Metadata_Well == "A01"))


sink(file("plan_without_index.txt", "w"), type="message")
memdb <- dplyr::src_sqlite(":memory:", create = T)
fac <- X %>% dplyr::select_(.dots = query_cols) %>% dplyr::mutate(index = 1:n)
fac <- dplyr::copy_to(memdb, fac)
cmat_df <-
  reshape2::melt(cmat) %>%
  tibble::as_data_frame() %>%
  dplyr::rename(index.x = Var1, index.y = Var2, sim_val = value)
cmat_df <- dplyr::copy_to(memdb, cmat_df,  indexes = list("index.x", "index.y"))
fac_outer %<>% dplyr::inner_join(cmat_df, by = c("index.x", "index.y"))
dplyr::explain(fac_outer)
sink(type="message")

sink(file("plan_with_index.txt", "w"), type="message")
memdb <- dplyr::src_sqlite(":memory:", create = T)
fac <- X %>% dplyr::select_(.dots = query_cols) %>% dplyr::mutate(index = 1:n)
fac <- dplyr::copy_to(memdb, fac, indexes = as.list(query_cols))
cmat_df <-
  reshape2::melt(cmat) %>%
  tibble::as_data_frame() %>%
  dplyr::rename(index.x = Var1, index.y = Var2, sim_val = value)
cmat_df <- dplyr::copy_to(memdb, cmat_df,  indexes = list("index.x", "index.y"))
fac_outer %<>% dplyr::inner_join(cmat_df, by = c("index.x", "index.y"))
dplyr::explain(fac_outer)
sink(type="message")

# 
# cmat_df <- dplyr::copy_to(memdb, cmat_df,  indexes = list("index.x", "index.y"))
# #cmat_df <- dplyr::copy_to(memdb, cmat_df)
# 
# fac_outer %<>% dplyr::inner_join(cmat_df, by = c("index.x", "index.y"))
# 
# dplyr::explain(fac_outer)
# futile.logger::flog.debug("Start collecting")
# #fac_outer %<>% dplyr::collect(n = Inf)
# futile.logger::flog.debug("End collecting")

```

